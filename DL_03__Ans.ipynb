{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LATHIKESHWARAN/DL-Image-Classifier-using-CNN/blob/main/DL_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Dwy4JH85p-hE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "zHgNmzcbVTFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name : vikash\n",
        "\n",
        "reg no: 212222240115"
      ],
      "metadata": {
        "id": "EI8q8p0ZfDl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root='../Data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GNfahnrVjj3",
        "outputId": "b8a7adb0-1880-42d2-d088-72e05f29f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 477kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.48MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.29MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "KQdCYr_aVmcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "sGzBX6wDVp0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "    break"
      ],
      "metadata": {
        "id": "LSBZmgbUVr55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1,28,28)  # 4D batch ( batch of 1 image)"
      ],
      "metadata": {
        "id": "q-ZDnTY5Vt_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
        "        self.fc1 = nn.Linear(5*5*16,120)\n",
        "        self.fc2 = nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = X.view(-1, 5*5*16)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = self.fc3(X)\n",
        "        return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "eK8ZepPOVwiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRGCp2jgVy3Y",
        "outputId": "c875d245-35e2-4358-9b25-80d07bfeb6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAME : Vikash s\n",
        "\n",
        "REG NO : 212222240115"
      ],
      "metadata": {
        "id": "y3ZquLFtfHaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "JQip2Se1V1tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Variables ( Trackers)\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# for loop epochs\n",
        "for i in range(epochs):\n",
        "\n",
        "    trn_corr = 0\n",
        "    tst_corr = 0\n",
        "\n",
        "\n",
        "    # Run the training batches\n",
        "    for b, (X_train, y_train) in enumerate(train_loader):\n",
        "        b+=1\n",
        "\n",
        "        # Apply the model\n",
        "        y_pred = model(X_train)  # we not flatten X-train here\n",
        "        loss = criterion(y_pred, y_train)\n",
        "\n",
        "\n",
        "        predicted = torch.max(y_pred.data, 1)[1]\n",
        "        batch_corr = (predicted == y_train).sum()  # Trure 1 / False 0 sum()\n",
        "        trn_corr += batch_corr\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print interim results\n",
        "        if b%600 == 0:\n",
        "            print(f'epoch: {i}  batch: {b} loss: {loss.item()}')\n",
        "\n",
        "    train_losses.append(loss)\n",
        "    train_correct.append(trn_corr)\n",
        "\n",
        "    # Run the testing batches\n",
        "    with torch.no_grad():\n",
        "        for b, (X_test, y_test) in enumerate(test_loader):\n",
        "\n",
        "            # Apply the model\n",
        "            y_val = model(X_test)\n",
        "\n",
        "            # Tally the number of correct predictions\n",
        "            predicted = torch.max(y_val.data, 1)[1]\n",
        "            tst_corr += (predicted == y_test).sum()\n",
        "\n",
        "    loss = criterion(y_val, y_test)\n",
        "    test_losses.append(loss)\n",
        "    test_correct.append(tst_corr)\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f'Training took {total/60} minutes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5WAZ0uTV4zD",
        "outputId": "6d5de705-89ca-4ca9-ca11-ae20eb0c4d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  batch: 600 loss: 0.04055630788207054\n",
            "epoch: 0  batch: 1200 loss: 0.08253484964370728\n",
            "epoch: 0  batch: 1800 loss: 0.36422696709632874\n",
            "epoch: 0  batch: 2400 loss: 0.018563708290457726\n",
            "epoch: 0  batch: 3000 loss: 0.008377513848245144\n",
            "epoch: 0  batch: 3600 loss: 0.002423502504825592\n",
            "epoch: 0  batch: 4200 loss: 0.5999186038970947\n",
            "epoch: 0  batch: 4800 loss: 0.020963605493307114\n",
            "epoch: 0  batch: 5400 loss: 0.005595742259174585\n",
            "epoch: 0  batch: 6000 loss: 0.04970256984233856\n",
            "epoch: 1  batch: 600 loss: 0.010842357762157917\n",
            "epoch: 1  batch: 1200 loss: 0.045671623200178146\n",
            "epoch: 1  batch: 1800 loss: 0.0014050878817215562\n",
            "epoch: 1  batch: 2400 loss: 0.06672239303588867\n",
            "epoch: 1  batch: 3000 loss: 0.31000304222106934\n",
            "epoch: 1  batch: 3600 loss: 0.00015608184912707657\n",
            "epoch: 1  batch: 4200 loss: 0.0009690290316939354\n",
            "epoch: 1  batch: 4800 loss: 0.0011280770413577557\n",
            "epoch: 1  batch: 5400 loss: 0.0008054501377046108\n",
            "epoch: 1  batch: 6000 loss: 0.04125749319791794\n",
            "epoch: 2  batch: 600 loss: 0.0021145944483578205\n",
            "epoch: 2  batch: 1200 loss: 0.003909791354089975\n",
            "epoch: 2  batch: 1800 loss: 0.002483351854607463\n",
            "epoch: 2  batch: 2400 loss: 0.002242229413241148\n",
            "epoch: 2  batch: 3000 loss: 0.14334513247013092\n",
            "epoch: 2  batch: 3600 loss: 0.034599967300891876\n",
            "epoch: 2  batch: 4200 loss: 0.028883133083581924\n",
            "epoch: 2  batch: 4800 loss: 0.006127307657152414\n",
            "epoch: 2  batch: 5400 loss: 0.0002179949078708887\n",
            "epoch: 2  batch: 6000 loss: 0.000285611575236544\n",
            "epoch: 3  batch: 600 loss: 0.00023542491544503719\n",
            "epoch: 3  batch: 1200 loss: 0.0006502759642899036\n",
            "epoch: 3  batch: 1800 loss: 6.997828313615173e-05\n",
            "epoch: 3  batch: 2400 loss: 3.2255047699436545e-05\n",
            "epoch: 3  batch: 3000 loss: 0.0007299475255422294\n",
            "epoch: 3  batch: 3600 loss: 0.005373741965740919\n",
            "epoch: 3  batch: 4200 loss: 0.00020280522585380822\n",
            "epoch: 3  batch: 4800 loss: 0.02023724466562271\n",
            "epoch: 3  batch: 5400 loss: 0.0026429318822920322\n",
            "epoch: 3  batch: 6000 loss: 0.0062173111364245415\n",
            "epoch: 4  batch: 600 loss: 0.002825820120051503\n",
            "epoch: 4  batch: 1200 loss: 0.04890861362218857\n",
            "epoch: 4  batch: 1800 loss: 0.0001377762237098068\n",
            "epoch: 4  batch: 2400 loss: 2.9609716875711456e-05\n",
            "epoch: 4  batch: 3000 loss: 0.0021401906851679087\n",
            "epoch: 4  batch: 3600 loss: 0.02274867706000805\n",
            "epoch: 4  batch: 4200 loss: 0.00015061507292557508\n",
            "epoch: 4  batch: 4800 loss: 0.006375586148351431\n",
            "epoch: 4  batch: 5400 loss: 0.002882108325138688\n",
            "epoch: 4  batch: 6000 loss: 0.000796707347035408\n",
            "Training took 2.9309089303016664 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the data all at once, not in batches\n",
        "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "aIM2c5UYWtLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    for X_test, y_test in test_load_all:\n",
        "        y_val = model(X_test)  # we don't flatten the data this time\n",
        "        predicted = torch.max(y_val,1)[1]\n",
        "        correct += (predicted == y_test).sum()"
      ],
      "metadata": {
        "id": "OBEPuhunWwKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw6cBNTuWx5g",
        "outputId": "6ae083a7-6437-4c8a-c4a9-adee251d2bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9881"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct.item()/len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAQN8PxpW05n",
        "outputId": "d209777d-a4ca-4aba-ae4e-3578d65306e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9881"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAME : Vikash s\n",
        "\n",
        "REG NO : 212222240115"
      ],
      "metadata": {
        "id": "FbWtaUB4fSx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print a row of values for reference\n",
        "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
        "print(np.arange(10).reshape(1,10))\n",
        "print()\n",
        "\n",
        "# print the confusion matrix\n",
        "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbPPlKJFW23o",
        "outputId": "a614121f-ed5a-4c62-8f76-f57a82563460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    1    2    3    4    5    6    7    8    9]]\n",
            "\n",
            "[[ 974    0    1    0    0    2    6    0    2    0]\n",
            " [   0 1134    2    0    0    0    2    3    0    3]\n",
            " [   2    0 1022    1    0    0    0    4    2    1]\n",
            " [   0    1    0 1005    0   19    0    0    1    0]\n",
            " [   0    0    1    0  976    0    2    0    2    5]\n",
            " [   0    0    0    2    0  852    2    0    0    2]\n",
            " [   2    0    0    0    1    3  944    0    0    0]\n",
            " [   1    0    6    0    0    1    0 1016    0    3]\n",
            " [   0    0    0    1    0    2    2    3  965    2]\n",
            " [   1    0    0    1    5   13    0    2    2  993]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single image for test\n",
        "plt.imshow(test_data[2000][0].reshape(28,28))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "cWNSaUdcXNM2",
        "outputId": "e2f4ef3b-6f56-4879-913d-3711c5f6101c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    new_prediction = model(test_data[2000][0].view(1,1,28,28))"
      ],
      "metadata": {
        "id": "S4J2lOJ3XPjt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_prediction.argmax()"
      ],
      "metadata": {
        "id": "Ffqjh6rMXSTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5660c9-9240-4f11-e495-fbd83739e82d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[2000][1]"
      ],
      "metadata": {
        "id": "x7GVTp4tXUv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc94e81-b5a3-4961-d9e3-56c6f73b8084"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'Lathikeshwaran_ex-3.pt')"
      ],
      "metadata": {
        "id": "uLjgN4DOXYVM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = ConvolutionalNetwork() # Replace Model with ConvolutionalNetwork\n",
        "new_model.load_state_dict(torch.load('Lathikeshwaran_ex-3.pt'))\n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "lCY1xbWiXgx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab74452-c980-41be-a8e6-509799e35726"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}